{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import recall_score, accuracy_score, classification_report, confusion_matrix, precision_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from time import time\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the cleaned data for ML models\n",
    "df2 = pd.read_csv(\"ML_diabetes_data.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "      <td>[60 - 70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>4.5</td>\n",
       "      <td>62</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>N</td>\n",
       "      <td>[20 - 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "      <td>[60 - 70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "      <td>[60 - 70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>7.1</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>N</td>\n",
       "      <td>[30 - 40)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender  Urea  Cr  HbA1c  Chol   TG  HDL  LDL  VLDL   BMI CLASS  age_range\n",
       "0      F   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0     N  [60 - 70)\n",
       "1      M   4.5  62    4.9   3.7  1.4  1.1  2.1   0.6  23.0     N  [20 - 30)\n",
       "2      F   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0     N  [60 - 70)\n",
       "3      F   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0     N  [60 - 70)\n",
       "4      M   7.1  46    4.9   4.9  1.0  0.8  2.0   0.4  21.0     N  [30 - 40)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels as numeric categories\n",
    "le1 = LabelEncoder()\n",
    "df2['Gender'] =le1.fit_transform(df2['Gender'])\n",
    "le2 = LabelEncoder()\n",
    "df2['CLASS'] =le2.fit_transform(df2['CLASS'])\n",
    "le3 = LabelEncoder()\n",
    "df2['age_range'] =le3.fit_transform(df2['age_range'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'P', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le2.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[20 - 30)', '[30 - 40)', '[40 - 50)', '[50 - 60)', '[60 - 70)',\n",
       "       '[70 - 80)', '[80 - 90)', '[90 - 100)'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le3.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>62</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>15.4</td>\n",
       "      <td>37.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>81</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>27.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>59</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Urea  Cr  HbA1c  Chol   TG  HDL  LDL  VLDL   BMI  CLASS  \\\n",
       "0         0   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0      0   \n",
       "1         1   4.5  62    4.9   3.7  1.4  1.1  2.1   0.6  23.0      0   \n",
       "2         0   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0      0   \n",
       "3         0   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0      0   \n",
       "4         1   7.1  46    4.9   4.9  1.0  0.8  2.0   0.4  21.0      0   \n",
       "..      ...   ...  ..    ...   ...  ...  ...  ...   ...   ...    ...   \n",
       "995       1  11.0  97    7.0   7.5  1.7  1.2  1.8   0.6  30.0      2   \n",
       "996       1   3.0  60   12.3   4.1  2.2  0.7  2.4  15.4  37.2      2   \n",
       "997       1   7.1  81    6.7   4.1  1.1  1.2  2.4   8.1  27.4      2   \n",
       "998       1   5.8  59    6.7   5.3  2.0  1.6  2.9  14.0  40.5      2   \n",
       "999       1   5.0  67    6.9   3.8  1.7  1.1  3.0   0.7  33.0      2   \n",
       "\n",
       "     age_range  \n",
       "0            4  \n",
       "1            0  \n",
       "2            4  \n",
       "3            4  \n",
       "4            1  \n",
       "..         ...  \n",
       "995          6  \n",
       "996          1  \n",
       "997          1  \n",
       "998          2  \n",
       "999          4  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are on different scales, as observed above. HbA1c is reported as a percentage in the lab, the reference range for creatinine is markedly larger than the rest of the analytes. \n",
    "\n",
    "This is where scaling comes in. We will use the MinMaxScaler() which will transform the features between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define scaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Urea_scaled</th>\n",
       "      <th>Cr_scaled</th>\n",
       "      <th>HbA1c_scaled</th>\n",
       "      <th>Chol_scaled</th>\n",
       "      <th>TG_scaled</th>\n",
       "      <th>HDL_scaled</th>\n",
       "      <th>LDL_scaled</th>\n",
       "      <th>VLDL_scaled</th>\n",
       "      <th>BMI_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.226804</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.070529</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.359223</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.014327</td>\n",
       "      <td>0.139130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.226804</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.226804</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.475728</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>0.069565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.114610</td>\n",
       "      <td>0.403974</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.014327</td>\n",
       "      <td>0.382609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.065104</td>\n",
       "      <td>0.068010</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.140741</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.438395</td>\n",
       "      <td>0.633043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.094458</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.059259</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.229226</td>\n",
       "      <td>0.292174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.066751</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.398281</td>\n",
       "      <td>0.747826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.076826</td>\n",
       "      <td>0.397351</td>\n",
       "      <td>0.368932</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.017192</td>\n",
       "      <td>0.486957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Urea_scaled  Cr_scaled  HbA1c_scaled  Chol_scaled  TG_scaled  HDL_scaled  \\\n",
       "0       0.109375   0.050378      0.264901     0.407767   0.044444    0.226804   \n",
       "1       0.104167   0.070529      0.264901     0.359223   0.081481    0.092784   \n",
       "2       0.109375   0.050378      0.264901     0.407767   0.044444    0.226804   \n",
       "3       0.109375   0.050378      0.264901     0.407767   0.044444    0.226804   \n",
       "4       0.171875   0.050378      0.264901     0.475728   0.051852    0.061856   \n",
       "..           ...        ...           ...          ...        ...         ...   \n",
       "995     0.273438   0.114610      0.403974     0.728155   0.103704    0.103093   \n",
       "996     0.065104   0.068010      0.754967     0.398058   0.140741    0.051546   \n",
       "997     0.171875   0.094458      0.384106     0.398058   0.059259    0.103093   \n",
       "998     0.138021   0.066751      0.384106     0.514563   0.125926    0.144330   \n",
       "999     0.117188   0.076826      0.397351     0.368932   0.103704    0.092784   \n",
       "\n",
       "     LDL_scaled  VLDL_scaled  BMI_scaled  \n",
       "0      0.114583     0.011461    0.173913  \n",
       "1      0.187500     0.014327    0.139130  \n",
       "2      0.114583     0.011461    0.173913  \n",
       "3      0.114583     0.011461    0.173913  \n",
       "4      0.177083     0.008596    0.069565  \n",
       "..          ...          ...         ...  \n",
       "995    0.156250     0.014327    0.382609  \n",
       "996    0.218750     0.438395    0.633043  \n",
       "997    0.218750     0.229226    0.292174  \n",
       "998    0.270833     0.398281    0.747826  \n",
       "999    0.281250     0.017192    0.486957  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define columns to scale \n",
    "columns_to_scale = ['Urea','Cr','HbA1c','Chol','TG','HDL','LDL','VLDL','BMI']\n",
    "columns_scaled = ['Urea_scaled','Cr_scaled','HbA1c_scaled','Chol_scaled','TG_scaled','HDL_scaled','LDL_scaled','VLDL_scaled','BMI_scaled']\n",
    "\n",
    "scale_values = df2[columns_to_scale].values\n",
    "scaled_array = scaler.fit_transform(scale_values)\n",
    "\n",
    "#create df_2 with scaled features\n",
    "df2_scaled = pd.DataFrame(scaled_array, columns=columns_scaled)\n",
    "df2_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>age_range</th>\n",
       "      <th>Urea_scaled</th>\n",
       "      <th>Cr_scaled</th>\n",
       "      <th>HbA1c_scaled</th>\n",
       "      <th>Chol_scaled</th>\n",
       "      <th>TG_scaled</th>\n",
       "      <th>HDL_scaled</th>\n",
       "      <th>LDL_scaled</th>\n",
       "      <th>VLDL_scaled</th>\n",
       "      <th>BMI_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.226804</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>62</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.070529</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.359223</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.014327</td>\n",
       "      <td>0.139130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.226804</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.226804</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.475728</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>0.069565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.114610</td>\n",
       "      <td>0.403974</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.014327</td>\n",
       "      <td>0.382609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>15.4</td>\n",
       "      <td>37.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065104</td>\n",
       "      <td>0.068010</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.140741</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.438395</td>\n",
       "      <td>0.633043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>81</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>27.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.094458</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.059259</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.229226</td>\n",
       "      <td>0.292174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>59</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.066751</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.398281</td>\n",
       "      <td>0.747826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.076826</td>\n",
       "      <td>0.397351</td>\n",
       "      <td>0.368932</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.017192</td>\n",
       "      <td>0.486957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Urea  Cr  HbA1c  Chol   TG  HDL  LDL  VLDL   BMI  ...  age_range  \\\n",
       "0         0   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0  ...          4   \n",
       "1         1   4.5  62    4.9   3.7  1.4  1.1  2.1   0.6  23.0  ...          0   \n",
       "2         0   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0  ...          4   \n",
       "3         0   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0  ...          4   \n",
       "4         1   7.1  46    4.9   4.9  1.0  0.8  2.0   0.4  21.0  ...          1   \n",
       "..      ...   ...  ..    ...   ...  ...  ...  ...   ...   ...  ...        ...   \n",
       "995       1  11.0  97    7.0   7.5  1.7  1.2  1.8   0.6  30.0  ...          6   \n",
       "996       1   3.0  60   12.3   4.1  2.2  0.7  2.4  15.4  37.2  ...          1   \n",
       "997       1   7.1  81    6.7   4.1  1.1  1.2  2.4   8.1  27.4  ...          1   \n",
       "998       1   5.8  59    6.7   5.3  2.0  1.6  2.9  14.0  40.5  ...          2   \n",
       "999       1   5.0  67    6.9   3.8  1.7  1.1  3.0   0.7  33.0  ...          4   \n",
       "\n",
       "     Urea_scaled  Cr_scaled  HbA1c_scaled  Chol_scaled  TG_scaled  HDL_scaled  \\\n",
       "0       0.109375   0.050378      0.264901     0.407767   0.044444    0.226804   \n",
       "1       0.104167   0.070529      0.264901     0.359223   0.081481    0.092784   \n",
       "2       0.109375   0.050378      0.264901     0.407767   0.044444    0.226804   \n",
       "3       0.109375   0.050378      0.264901     0.407767   0.044444    0.226804   \n",
       "4       0.171875   0.050378      0.264901     0.475728   0.051852    0.061856   \n",
       "..           ...        ...           ...          ...        ...         ...   \n",
       "995     0.273438   0.114610      0.403974     0.728155   0.103704    0.103093   \n",
       "996     0.065104   0.068010      0.754967     0.398058   0.140741    0.051546   \n",
       "997     0.171875   0.094458      0.384106     0.398058   0.059259    0.103093   \n",
       "998     0.138021   0.066751      0.384106     0.514563   0.125926    0.144330   \n",
       "999     0.117188   0.076826      0.397351     0.368932   0.103704    0.092784   \n",
       "\n",
       "     LDL_scaled  VLDL_scaled  BMI_scaled  \n",
       "0      0.114583     0.011461    0.173913  \n",
       "1      0.187500     0.014327    0.139130  \n",
       "2      0.114583     0.011461    0.173913  \n",
       "3      0.114583     0.011461    0.173913  \n",
       "4      0.177083     0.008596    0.069565  \n",
       "..          ...          ...         ...  \n",
       "995    0.156250     0.014327    0.382609  \n",
       "996    0.218750     0.438395    0.633043  \n",
       "997    0.218750     0.229226    0.292174  \n",
       "998    0.270833     0.398281    0.747826  \n",
       "999    0.281250     0.017192    0.486957  \n",
       "\n",
       "[1000 rows x 21 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate df2 and df2_scaled to form df3\n",
    "df3 = pd.concat([df2,df2_scaled],axis=1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training, validation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "X = df3[['Gender','age_range','Urea_scaled','Cr_scaled','HbA1c_scaled','Chol_scaled','TG_scaled','HDL_scaled','LDL_scaled','VLDL_scaled','BMI_scaled']].values\n",
    "y = df3['CLASS'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.40,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,test_size=0.50,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "for dataset in [y_train, y_val, y_test]:\n",
    "    print(round(len(dataset) /  len(y), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    # Print the best hyperparameters\n",
    "    print(\"BEST PARAMS: {}\\n\".format(results.best_params_))\n",
    "    \n",
    "    # Extract mean test scores and standard deviations\n",
    "    means = results.cv_results_[\"mean_test_score\"]\n",
    "    stds = results.cv_results_[\"std_test_score\"]\n",
    "    \n",
    "    # Iterate through mean scores, standard deviations, and parameters\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_[\"params\"]):\n",
    "        # Print the mean score and its standard deviation, rounded to 3 decimal places\n",
    "        # Also, print the corresponding hyperparameters\n",
    "        print(\"{} (+/-{}) for {}\".format(round(mean, 3), round(std * 2, 3), params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 100}\n",
      "\n",
      "0.84 (+/-0.007) for {'C': 0.001}\n",
      "0.842 (+/-0.011) for {'C': 0.01}\n",
      "0.855 (+/-0.025) for {'C': 0.1}\n",
      "0.898 (+/-0.039) for {'C': 1}\n",
      "0.905 (+/-0.037) for {'C': 10}\n",
      "0.917 (+/-0.024) for {'C': 100}\n",
      "0.917 (+/-0.024) for {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression model with increased max_iter\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Define the hyperparameters you want to search over\n",
    "parameters = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Create a grid search object with cross-validation\n",
    "cv = GridSearchCV(lr, parameters, cv=5)\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the results using the print_results function\n",
    "print_results(cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR_model.pkl']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(cv.best_estimator_, \"LR_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "0.84 (+/-0.007) for {'C': 0.001, 'kernel': 'linear'}\n",
      "0.84 (+/-0.007) for {'C': 0.001, 'kernel': 'rbf'}\n",
      "0.84 (+/-0.007) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.84 (+/-0.007) for {'C': 0.01, 'kernel': 'rbf'}\n",
      "0.84 (+/-0.007) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.84 (+/-0.007) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.91 (+/-0.037) for {'C': 1, 'kernel': 'linear'}\n",
      "0.837 (+/-0.013) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.913 (+/-0.037) for {'C': 10, 'kernel': 'linear'}\n",
      "0.893 (+/-0.034) for {'C': 10, 'kernel': 'rbf'}\n",
      "0.922 (+/-0.039) for {'C': 100, 'kernel': 'linear'}\n",
      "0.915 (+/-0.034) for {'C': 100, 'kernel': 'rbf'}\n",
      "0.932 (+/-0.037) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.92 (+/-0.034) for {'C': 1000, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "#create a svc model\n",
    "\n",
    "svc = SVC()\n",
    "parameters = {\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Create a grid search object with cross-validation\n",
    "cv = GridSearchCV(svc, parameters, cv=5)\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the results using the print_results function\n",
    "print_results(cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1000, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "print(cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM_model.pkl']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write out pickled model\n",
    "joblib.dump(cv.best_estimator_, \"SVM_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 8, 'n_estimators': 20}\n",
      "\n",
      "0.902 (+/-0.027) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.903 (+/-0.031) for {'max_depth': 2, 'n_estimators': 20}\n",
      "0.892 (+/-0.021) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.905 (+/-0.031) for {'max_depth': 2, 'n_estimators': 100}\n",
      "0.952 (+/-0.049) for {'max_depth': 4, 'n_estimators': 5}\n",
      "0.967 (+/-0.0) for {'max_depth': 4, 'n_estimators': 20}\n",
      "0.96 (+/-0.019) for {'max_depth': 4, 'n_estimators': 50}\n",
      "0.97 (+/-0.017) for {'max_depth': 4, 'n_estimators': 100}\n",
      "0.967 (+/-0.015) for {'max_depth': 8, 'n_estimators': 5}\n",
      "0.977 (+/-0.019) for {'max_depth': 8, 'n_estimators': 20}\n",
      "0.972 (+/-0.023) for {'max_depth': 8, 'n_estimators': 50}\n",
      "0.973 (+/-0.027) for {'max_depth': 8, 'n_estimators': 100}\n",
      "0.965 (+/-0.024) for {'max_depth': 16, 'n_estimators': 5}\n",
      "0.972 (+/-0.025) for {'max_depth': 16, 'n_estimators': 20}\n",
      "0.972 (+/-0.023) for {'max_depth': 16, 'n_estimators': 50}\n",
      "0.972 (+/-0.02) for {'max_depth': 16, 'n_estimators': 100}\n",
      "0.967 (+/-0.038) for {'max_depth': 32, 'n_estimators': 5}\n",
      "0.97 (+/-0.027) for {'max_depth': 32, 'n_estimators': 20}\n",
      "0.972 (+/-0.023) for {'max_depth': 32, 'n_estimators': 50}\n",
      "0.973 (+/-0.024) for {'max_depth': 32, 'n_estimators': 100}\n",
      "0.965 (+/-0.019) for {'max_depth': 64, 'n_estimators': 5}\n",
      "0.97 (+/-0.017) for {'max_depth': 64, 'n_estimators': 20}\n",
      "0.973 (+/-0.022) for {'max_depth': 64, 'n_estimators': 50}\n",
      "0.97 (+/-0.013) for {'max_depth': 64, 'n_estimators': 100}\n",
      "0.958 (+/-0.024) for {'max_depth': None, 'n_estimators': 5}\n",
      "0.973 (+/-0.012) for {'max_depth': None, 'n_estimators': 20}\n",
      "0.97 (+/-0.013) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.97 (+/-0.023) for {'max_depth': None, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Classifier  model  \n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "parameters = {\n",
    "    \"n_estimators\": [5, 20, 50, 100],\n",
    "    \"max_depth\": [2, 4, 8, 16, 32, 64, None]\n",
    "}\n",
    "\n",
    "# Create a grid search object with cross-validation\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the results using the print_results function\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Random_forest_model.pkl']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write out pickled model\n",
    "joblib.dump(cv.best_estimator_, \"Random_forest_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "0.883 (+/-0.018) for {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.903 (+/-0.027) for {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.865 (+/-0.037) for {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.897 (+/-0.031) for {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.857 (+/-0.034) for {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.897 (+/-0.025) for {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.827 (+/-0.063) for {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "0.877 (+/-0.049) for {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "0.883 (+/-0.018) for {'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.903 (+/-0.027) for {'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.865 (+/-0.037) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.897 (+/-0.031) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.857 (+/-0.034) for {'algorithm': 'kd_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.897 (+/-0.025) for {'algorithm': 'kd_tree', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.827 (+/-0.063) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "0.877 (+/-0.049) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "0.883 (+/-0.018) for {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.903 (+/-0.027) for {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.865 (+/-0.037) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.897 (+/-0.031) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.857 (+/-0.034) for {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.897 (+/-0.025) for {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.827 (+/-0.063) for {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "0.877 (+/-0.049) for {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Create a KNN model  \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "parameters = {\n",
    "    'n_neighbors': [3, 5, 7, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'kd_tree', 'ball_tree'],\n",
    "}\n",
    "\n",
    "\n",
    "# Create a grid search object with cross-validation\n",
    "cv = GridSearchCV(knn, parameters, cv=5)\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the results using the print_results function\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNN_model.pkl']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write out pickled model\n",
    "joblib.dump(cv.best_estimator_, \"KNN_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "\n",
      "0.84 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.84 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.95 (+/-0.015) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.84 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.947 (+/-0.008) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.982 (+/-0.012) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.84 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.958 (+/-0.011) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.975 (+/-0.024) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.84 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.963 (+/-0.023) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.973 (+/-0.024) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.84 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.967 (+/-0.024) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.973 (+/-0.024) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.84 (+/-0.007) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.977 (+/-0.019) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.977 (+/-0.029) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.963 (+/-0.027) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.987 (+/-0.008) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.982 (+/-0.019) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.972 (+/-0.025) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.977 (+/-0.016) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.977 (+/-0.012) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.967 (+/-0.03) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.973 (+/-0.029) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.973 (+/-0.024) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.967 (+/-0.03) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.973 (+/-0.029) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.972 (+/-0.025) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.902 (+/-0.08) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.908 (+/-0.098) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.898 (+/-0.096) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.973 (+/-0.019) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.977 (+/-0.024) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.975 (+/-0.03) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.98 (+/-0.017) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.985 (+/-0.012) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.983 (+/-0.015) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.972 (+/-0.034) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.968 (+/-0.039) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.972 (+/-0.04) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.972 (+/-0.029) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.968 (+/-0.032) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.97 (+/-0.037) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.69 (+/-0.598) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.69 (+/-0.598) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.69 (+/-0.598) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.852 (+/-0.044) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.853 (+/-0.045) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.853 (+/-0.045) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.98 (+/-0.017) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.975 (+/-0.026) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.977 (+/-0.027) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.973 (+/-0.032) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.975 (+/-0.035) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.973 (+/-0.032) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.972 (+/-0.043) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.973 (+/-0.04) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.975 (+/-0.03) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.853 (+/-0.037) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.853 (+/-0.037) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.853 (+/-0.037) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.708 (+/-0.601) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.708 (+/-0.601) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.708 (+/-0.601) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.972 (+/-0.025) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.972 (+/-0.037) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.975 (+/-0.028) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.967 (+/-0.035) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.968 (+/-0.031) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.973 (+/-0.019) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.968 (+/-0.031) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.972 (+/-0.023) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.968 (+/-0.031) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "# Create a Gb model  \n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "\n",
    "# Create a grid search object with cross-validation\n",
    "cv = GridSearchCV(gb, parameters, cv=5)\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the results using the print_results function\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb_model.pkl']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write out pickled model\n",
    "joblib.dump(cv.best_estimator_, \"gb_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in saved models for Validation and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in [\"LR\", \"SVM\", \"KNN\", \"gb\", \"Random_Forest\"]:\n",
    "    models[mdl] = joblib.load(\"{}_model.pkl\".format(mdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LogisticRegression(C=100, max_iter=1000),\n",
       " 'SVM': SVC(C=1000, kernel='linear'),\n",
       " 'KNN': KNeighborsClassifier(n_neighbors=3, weights='distance'),\n",
       " 'gb': GradientBoostingClassifier(n_estimators=50),\n",
       " 'Random_Forest': RandomForestClassifier(max_depth=8, n_estimators=20)}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred, average='weighted'), 3)\n",
    "    recall = round(recall_score(labels, pred, average='weighted'), 3)\n",
    "    print('{} -- Accuracy: {} / Precision: {} / Recall: {} / Latency: {}ms'.format(name,\n",
    "                                                                                   accuracy,\n",
    "                                                                                   precision,\n",
    "                                                                                   recall,\n",
    "                                                                                   round((end - start)*1000, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR -- Accuracy: 0.925 / Precision: 0.917 / Recall: 0.925 / Latency: 0.0ms\n",
      "SVM -- Accuracy: 0.935 / Precision: 0.931 / Recall: 0.935 / Latency: 1.3ms\n",
      "KNN -- Accuracy: 0.955 / Precision: 0.965 / Recall: 0.955 / Latency: 2.5ms\n",
      "gb -- Accuracy: 0.97 / Precision: 0.97 / Recall: 0.97 / Latency: 1.0ms\n",
      "Random_Forest -- Accuracy: 0.98 / Precision: 0.98 / Recall: 0.98 / Latency: 3.3ms\n"
     ]
    }
   ],
   "source": [
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two best performing models are Gradient Boost and Random Forest. We will go ahead and evaluate their performances further using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest -- Accuracy: 0.98 / Precision: 0.981 / Recall: 0.98 / Latency: 4.7ms\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"Random Forest\", models[\"Random_Forest\"], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost -- Accuracy: 0.99 / Precision: 0.99 / Recall: 0.99 / Latency: 2.0ms\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"Gradient Boost\", models[\"gb\"], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting performed better on the testing set even though it was slightly bested by the random forest model on the validation set. We will take the gradient boosting model as the overall best model and explore it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further explore the Gradient boost model\n",
    "\n",
    "GBClassifier_model = GradientBoostingClassifier(n_estimators=50)\n",
    "GBClassifier_model_fitted = GBClassifier_model.fit(X_train,y_train)\n",
    "GBClassifier_model_prediction = GBClassifier_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Classifier Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        26\n",
      "           1       1.00      0.91      0.95        11\n",
      "           2       0.99      0.99      0.99       163\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       0.99      0.97      0.98       200\n",
      "weighted avg       0.99      0.99      0.99       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report for GB Classifier\n",
    "print('GB Classifier Report:\\n', classification_report(y_test,GBClassifier_model_prediction,target_names=['0','1','2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the model seems to perform very well, with high precision, recall, and F1-scores for most classes, and a high overall accuracy of 0.99. However, it's worth investigating the lower recall for class 1 to understand why some instances of this class were not correctly predicted. Class 0 represents no diabetes, class 1 prediabetes aand class 2 diabetess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1720be55880>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix for GBClassifier\n",
    "GBClassifier_matrix = confusion_matrix(y_test,GBClassifier_model_prediction)\n",
    "GBClassifier_confusion_matrix_display = ConfusionMatrixDisplay(GBClassifier_matrix)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "GBClassifier_confusion_matrix_display.plot(cmap=plt.cm.Blues,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
